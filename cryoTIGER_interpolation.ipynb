{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f195bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryocat import cryomap  # For handling cryo-ET .mrc file formats\n",
    "from pathlib import Path  # For file path manipulations\n",
    "from PIL import Image  # For image processing\n",
    "import imageio  # For saving image files\n",
    "\n",
    "# Read the MRC file using cryomap\n",
    "mrc = cryomap.read('tutorial_data/experimental_TS/0248_dose-filt_ali_bin8.mrc')\n",
    "\n",
    "# Normalize the MRC data to 0–255 range and convert to uint8 format\n",
    "mrc = ((mrc - mrc.min()) * (1 / (mrc.max() - mrc.min()) * 255)).astype('uint8')\n",
    "\n",
    "# Define the path to save generated PNG files\n",
    "PATH_ORIG = f'tutorial_data/orig'\n",
    "Path(PATH_ORIG).mkdir(parents=True, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Iterate through slices along the Z-axis of the MRC volume and save as PNGs\n",
    "for i in range(0, mrc.shape[2]):  # Loop through the third dimension (Z)\n",
    "    image = Image.fromarray(mrc[:, :, i])  # Extract 2D slice\n",
    "    if image.mode != 'RGB':  # Ensure image is in RGB format\n",
    "        image = image.convert('RGB')\n",
    "    imageio.imwrite(f'{PATH_ORIG}/{(i * 10):04}.png', image)  # Save as PNG with incremented name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a7d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 10:40:49.940049: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-16 10:41:33.909489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ms/tomajtne/.conda/envs/dl/lib/\n",
      "2024-12-16 10:41:33.909640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ms/tomajtne/.conda/envs/dl/lib/\n",
      "2024-12-16 10:41:33.909651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "I1216 10:42:42.520946 140437194561344 environments.py:376] Default Python SDK image for environment is apache/beam_python3.9_sdk:2.46.0\n",
      "I1216 10:42:42.570827 140437194561344 translations.py:710] ==================== <function annotate_downstream_side_inputs at 0x7fb7e96ac310> ====================\n",
      "I1216 10:42:42.571160 140437194561344 translations.py:710] ==================== <function fix_side_input_pcoll_coders at 0x7fb7e96ac430> ====================\n",
      "I1216 10:42:42.571352 140437194561344 translations.py:710] ==================== <function pack_combiners at 0x7fb7e96ac940> ====================\n",
      "I1216 10:42:42.571794 140437194561344 translations.py:710] ==================== <function lift_combiners at 0x7fb7e96ac9d0> ====================\n",
      "I1216 10:42:42.571935 140437194561344 translations.py:710] ==================== <function expand_sdf at 0x7fb7e96acb80> ====================\n",
      "I1216 10:42:42.572100 140437194561344 translations.py:710] ==================== <function expand_gbk at 0x7fb7e96acc10> ====================\n",
      "I1216 10:42:42.572217 140437194561344 translations.py:710] ==================== <function sink_flattens at 0x7fb7e96acd30> ====================\n",
      "I1216 10:42:42.572360 140437194561344 translations.py:710] ==================== <function greedily_fuse at 0x7fb7e96acdc0> ====================\n",
      "I1216 10:42:42.572712 140437194561344 translations.py:710] ==================== <function read_to_impulse at 0x7fb7e96ace50> ====================\n",
      "I1216 10:42:42.572825 140437194561344 translations.py:710] ==================== <function impulse_to_input at 0x7fb7e96acee0> ====================\n",
      "I1216 10:42:42.572983 140437194561344 translations.py:710] ==================== <function sort_stages at 0x7fb7e96ae160> ====================\n",
      "I1216 10:42:42.573162 140437194561344 translations.py:710] ==================== <function add_impulse_to_dangling_transforms at 0x7fb7e96ae280> ====================\n",
      "I1216 10:42:42.573264 140437194561344 translations.py:710] ==================== <function setup_timer_mapping at 0x7fb7e96ae0d0> ====================\n",
      "I1216 10:42:42.573405 140437194561344 translations.py:710] ==================== <function populate_data_channel_coders at 0x7fb7e96ae1f0> ====================\n",
      "I1216 10:42:42.574860 140437194561344 statecache.py:234] Creating state cache with size 104857600\n",
      "I1216 10:42:42.576205 140437194561344 worker_handlers.py:903] Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7fb7e94a9f70> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "I1216 10:42:42.576989 140437194561344 environments.py:376] Default Python SDK image for environment is apache/beam_python3.9_sdk:2.46.0\n",
      "I1216 10:42:56.447373 140437194561344 interpolator_cli.py:170] Generating in-between frames for tutorial_data/orig.\n",
      "100%|\u001b[32m█████████████████████████████████████████████████████████████\u001b[0m| 110/110 [01:16<00:00,  1.43it/s]\u001b[0m\n",
      "100%|\u001b[32m█████████████████████████████████████████████████████████████\u001b[0m| 221/221 [00:21<00:00, 10.52it/s]\u001b[0m\n",
      "I1216 10:44:34.372742 140437194561344 interpolator_cli.py:149] Output frames saved in tutorial_data/orig/interpolated_frames.\n",
      "2024-12-16 10:44:47.654798: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-16 10:45:08.373012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ms/tomajtne/.conda/envs/dl/lib/\n",
      "2024-12-16 10:45:08.373094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ms/tomajtne/.conda/envs/dl/lib/\n",
      "2024-12-16 10:45:08.373101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "I1216 10:46:08.843985 139904722995008 environments.py:376] Default Python SDK image for environment is apache/beam_python3.9_sdk:2.46.0\n",
      "I1216 10:46:08.866876 139904722995008 translations.py:710] ==================== <function annotate_downstream_side_inputs at 0x7f3be0313310> ====================\n",
      "I1216 10:46:08.867033 139904722995008 translations.py:710] ==================== <function fix_side_input_pcoll_coders at 0x7f3be0313430> ====================\n",
      "I1216 10:46:08.867108 139904722995008 translations.py:710] ==================== <function pack_combiners at 0x7f3be0313940> ====================\n",
      "I1216 10:46:08.867307 139904722995008 translations.py:710] ==================== <function lift_combiners at 0x7f3be03139d0> ====================\n",
      "I1216 10:46:08.867368 139904722995008 translations.py:710] ==================== <function expand_sdf at 0x7f3be0313b80> ====================\n",
      "I1216 10:46:08.867435 139904722995008 translations.py:710] ==================== <function expand_gbk at 0x7f3be0313c10> ====================\n",
      "I1216 10:46:08.867484 139904722995008 translations.py:710] ==================== <function sink_flattens at 0x7f3be0313d30> ====================\n",
      "I1216 10:46:08.867559 139904722995008 translations.py:710] ==================== <function greedily_fuse at 0x7f3be0313dc0> ====================\n",
      "I1216 10:46:08.867716 139904722995008 translations.py:710] ==================== <function read_to_impulse at 0x7f3be0313e50> ====================\n",
      "I1216 10:46:08.867765 139904722995008 translations.py:710] ==================== <function impulse_to_input at 0x7f3be0313ee0> ====================\n",
      "I1216 10:46:08.867830 139904722995008 translations.py:710] ==================== <function sort_stages at 0x7f3be0314160> ====================\n",
      "I1216 10:46:08.867911 139904722995008 translations.py:710] ==================== <function add_impulse_to_dangling_transforms at 0x7f3be0314280> ====================\n",
      "I1216 10:46:08.867955 139904722995008 translations.py:710] ==================== <function setup_timer_mapping at 0x7f3be03140d0> ====================\n",
      "I1216 10:46:08.868017 139904722995008 translations.py:710] ==================== <function populate_data_channel_coders at 0x7f3be03141f0> ====================\n",
      "I1216 10:46:08.868676 139904722995008 statecache.py:234] Creating state cache with size 104857600\n",
      "I1216 10:46:08.869532 139904722995008 worker_handlers.py:903] Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f3be01130d0> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n",
      "I1216 10:46:08.869894 139904722995008 environments.py:376] Default Python SDK image for environment is apache/beam_python3.9_sdk:2.46.0\n",
      "I1216 10:46:13.488507 139904722995008 interpolator_cli.py:170] Generating in-between frames for tutorial_data/orig.\n",
      "100%|\u001b[32m█████████████████████████████████████████████████████████████\u001b[0m| 110/110 [00:23<00:00,  4.69it/s]\u001b[0m\n",
      "100%|\u001b[32m█████████████████████████████████████████████████████████████\u001b[0m| 221/221 [00:20<00:00, 10.79it/s]\u001b[0m\n",
      "I1216 10:46:57.427614 139904722995008 interpolator_cli.py:149] Output frames saved in tutorial_data/orig/interpolated_frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tutorial_data/interpolated_frames_pre-trained_model'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp  # For running external commands\n",
    "import shutil  # For file operations\n",
    "import os  # For OS-level operations\n",
    "\n",
    "# Define path to original PNGs\n",
    "PATH_ORIG = 'tutorial_data/orig'\n",
    "\n",
    "# Define base path for storing interpolated results\n",
    "PATH_BASE = 'tutorial_data/tilts_cryoTIGER_model'\n",
    "\n",
    "# Run interpolation using the cryoTIGER model\n",
    "process = sp.Popen(f'python3 -m eval.interpolator_cli --pattern \"{PATH_ORIG}\" \\\n",
    "                    --model_path models/cryoTIGER_model \\\n",
    "                    --times_to_interpolate 1', shell=True)\n",
    "process.wait()  # Wait for process to complete\n",
    "\n",
    "# Move interpolated frames generated by the cryoTIGER model to a specific folder\n",
    "if os.path.exists(\"tutorial_data/interpolated_frames_cryoTIGER_model\"):\n",
    "    shutil.rmtree(\"tutorial_data/interpolated_frames_cryoTIGER_model\")  # Remove existing folder if it exists\n",
    "shutil.move(f\"{PATH_ORIG}/interpolated_frames\", \"tutorial_data/interpolated_frames_cryoTIGER_model\")\n",
    "\n",
    "# Run interpolation using the pre-trained Vimeo-90K model\n",
    "process = sp.Popen(f'python3 -m eval.interpolator_cli --pattern \"{PATH_ORIG}\" \\\n",
    "                    --model_path models/pre-trained_Vimeo-90K_data_model \\\n",
    "                    --times_to_interpolate 1', shell=True)\n",
    "process.wait()  # Wait for process to complete\n",
    "\n",
    "# Move interpolated frames generated by the Vimeo-90K model to a specific folder\n",
    "if os.path.exists(\"tutorial_data/interpolated_frames_pre-trained_model\"):\n",
    "    shutil.rmtree(\"tutorial_data/interpolated_frames_pre-trained_model\")  # Remove existing folder if it exists\n",
    "shutil.move(f\"{PATH_ORIG}/interpolated_frames\", \"tutorial_data/interpolated_frames_pre-trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0211689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryocat import cryomap  # For handling cryo-ET .mrc file formats\n",
    "from PIL import Image  # For image processing\n",
    "from os import listdir  # For directory listing\n",
    "import imageio.v3 as iio  # For reading images\n",
    "import numpy as np  # For numerical operations\n",
    "\n",
    "# Function to process interpolated frames and save them as an MRC file\n",
    "def process_interpolated_frames(input_path, output_filename):\n",
    "    \n",
    "    tomo3d = []  # Initialize list to store 2D slices\n",
    "    for tomo in sorted(listdir(input_path)):  # Process each file in sorted order\n",
    "        img = Image.open(f'{input_path}/{tomo}').convert('L')  # Convert image to grayscale\n",
    "        img.save(f'{input_path}/{tomo}')  # Save the converted image (overwrite)\n",
    "        \n",
    "        im = iio.imread(f'{input_path}/{tomo}')  # Read image data\n",
    "        tomo3d.append(im)  # Append slice to list\n",
    "    \n",
    "    # Stack 2D slices along the Z-axis to reconstruct a 3D volume\n",
    "    tomo3d = np.stack(tomo3d, axis=2)\n",
    "    \n",
    "    # Save the reconstructed 3D volume as an MRC file\n",
    "    cryomap.write(tomo3d, output_filename, data_type=np.single)\n",
    "\n",
    "# Process interpolated frames for the cryoTIGER model\n",
    "PATH_GEN = f'tutorial_data/interpolated_frames_cryoTIGER_model/'\n",
    "process_interpolated_frames(PATH_GEN, f\"tutorial_data/interpolated_TS/demo_tilt_series_bin8_interpolated_cryoTIGER_model.mrc\")\n",
    "\n",
    "# Process interpolated frames for the pre-trained Vimeo-90K model\n",
    "PATH_GEN = f'tutorial_data/interpolated_frames_pre-trained_model/'\n",
    "process_interpolated_frames(PATH_GEN, f\"tutorial_data/interpolated_TS/demo_tilt_series_bin8_interpolated_pre-trained_model.mrc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "film_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
